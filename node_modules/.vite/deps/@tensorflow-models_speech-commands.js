import {
  exports_layers_exports,
  loadLayersModel,
  model,
  sequential
} from "./chunk-HJEXW4TU.js";
import {
  array,
  require_fs,
  zip
} from "./chunk-KXVD7KNM.js";
import {
  Tensor,
  add,
  argMax,
  backend,
  cast,
  dispose,
  div,
  gather,
  io_exports,
  max,
  mean,
  moments,
  mul,
  oneHot,
  require_util,
  scalar,
  slice,
  sqrt,
  squeeze,
  stack,
  sub,
  tensor,
  tensor1d,
  tensor2d,
  tensor3d,
  tensor4d,
  tidy,
  unstack,
  util_exports,
  zeros
} from "./chunk-SW6JV2BF.js";
import {
  __toESM
} from "./chunk-V4OQ3NZ2.js";

// node_modules/@tensorflow-models/speech-commands/dist/speech-commands.esm.js
var import_util = __toESM(require_util());
var extendStatics = function(e, t) {
  return (extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(e2, t2) {
    e2.__proto__ = t2;
  } || function(e2, t2) {
    for (var r in t2) t2.hasOwnProperty(r) && (e2[r] = t2[r]);
  })(e, t);
};
function __extends(e, t) {
  function r() {
    this.constructor = e;
  }
  extendStatics(e, t), e.prototype = null === t ? Object.create(t) : (r.prototype = t.prototype, new r());
}
var __assign = function() {
  return (__assign = Object.assign || function(e) {
    for (var t, r = 1, n = arguments.length; r < n; r++) for (var a in t = arguments[r]) Object.prototype.hasOwnProperty.call(t, a) && (e[a] = t[a]);
    return e;
  }).apply(this, arguments);
};
function __awaiter(e, t, r, n) {
  return new (r || (r = Promise))(function(a, i) {
    function o(e2) {
      try {
        l(n.next(e2));
      } catch (e3) {
        i(e3);
      }
    }
    function s(e2) {
      try {
        l(n.throw(e2));
      } catch (e3) {
        i(e3);
      }
    }
    function l(e2) {
      var t2;
      e2.done ? a(e2.value) : (t2 = e2.value, t2 instanceof r ? t2 : new r(function(e3) {
        e3(t2);
      })).then(o, s);
    }
    l((n = n.apply(e, t || [])).next());
  });
}
function __generator(e, t) {
  var r, n, a, i, o = { label: 0, sent: function() {
    if (1 & a[0]) throw a[1];
    return a[1];
  }, trys: [], ops: [] };
  return i = { next: s(0), throw: s(1), return: s(2) }, "function" == typeof Symbol && (i[Symbol.iterator] = function() {
    return this;
  }), i;
  function s(i2) {
    return function(s2) {
      return function(i3) {
        if (r) throw new TypeError("Generator is already executing.");
        for (; o; ) try {
          if (r = 1, n && (a = 2 & i3[0] ? n.return : i3[0] ? n.throw || ((a = n.return) && a.call(n), 0) : n.next) && !(a = a.call(n, i3[1])).done) return a;
          switch (n = 0, a && (i3 = [2 & i3[0], a.value]), i3[0]) {
            case 0:
            case 1:
              a = i3;
              break;
            case 4:
              return o.label++, { value: i3[1], done: false };
            case 5:
              o.label++, n = i3[1], i3 = [0];
              continue;
            case 7:
              i3 = o.ops.pop(), o.trys.pop();
              continue;
            default:
              if (!(a = (a = o.trys).length > 0 && a[a.length - 1]) && (6 === i3[0] || 2 === i3[0])) {
                o = 0;
                continue;
              }
              if (3 === i3[0] && (!a || i3[1] > a[0] && i3[1] < a[3])) {
                o.label = i3[1];
                break;
              }
              if (6 === i3[0] && o.label < a[1]) {
                o.label = a[1], a = i3;
                break;
              }
              if (a && o.label < a[2]) {
                o.label = a[2], o.ops.push(i3);
                break;
              }
              a[2] && o.ops.pop(), o.trys.pop();
              continue;
          }
          i3 = t.call(e, o);
        } catch (e2) {
          i3 = [6, e2], n = 0;
        } finally {
          r = a = 0;
        }
        if (5 & i3[0]) throw i3[1];
        return { value: i3[0] ? i3[1] : void 0, done: true };
      }([i2, s2]);
    };
  }
}
function __values(e) {
  var t = "function" == typeof Symbol && Symbol.iterator, r = t && e[t], n = 0;
  if (r) return r.call(e);
  if (e && "number" == typeof e.length) return { next: function() {
    return e && n >= e.length && (e = void 0), { value: e && e[n++], done: !e };
  } };
  throw new TypeError(t ? "Object is not iterable." : "Symbol.iterator is not defined.");
}
function __read(e, t) {
  var r = "function" == typeof Symbol && e[Symbol.iterator];
  if (!r) return e;
  var n, a, i = r.call(e), o = [];
  try {
    for (; (void 0 === t || t-- > 0) && !(n = i.next()).done; ) o.push(n.value);
  } catch (e2) {
    a = { error: e2 };
  } finally {
    try {
      n && !n.done && (r = i.return) && r.call(i);
    } finally {
      if (a) throw a.error;
    }
  }
  return o;
}
function __spread() {
  for (var e = [], t = 0; t < arguments.length; t++) e = e.concat(__read(arguments[t]));
  return e;
}
function loadMetadataJson(e) {
  return __awaiter(this, void 0, void 0, function() {
    var t, r, n, a, i, o, s;
    return __generator(this, function(l) {
      switch (l.label) {
        case 0:
          return t = "http://", r = "https://", n = "file://", 0 !== e.indexOf(t) && 0 !== e.indexOf(r) ? [3, 3] : [4, fetch(e)];
        case 1:
          return [4, l.sent().json()];
        case 2:
          return [2, l.sent()];
        case 3:
          return 0 !== e.indexOf(n) ? [3, 5] : (a = require_fs(), i = (0, import_util.promisify)(a.readFile), s = (o = JSON).parse, [4, i(e.slice(n.length), { encoding: "utf-8" })]);
        case 4:
          return [2, s.apply(o, [l.sent()])];
        case 5:
          throw new Error("Unsupported URL scheme in metadata URL: " + e + ". Supported schemes are: http://, https://, and (node.js-only) file://");
      }
    });
  });
}
var EPSILON = null;
function normalize(e) {
  return null == EPSILON && (EPSILON = backend().epsilon()), tidy(function() {
    var t = moments(e), r = t.mean, n = t.variance;
    return div(sub(e, r), add(sqrt(n), EPSILON));
  });
}
function normalizeFloat32Array(e) {
  if (e.length < 2) throw new Error("Cannot normalize a Float32Array with fewer than 2 elements.");
  return null == EPSILON && (EPSILON = backend().epsilon()), tidy(function() {
    var t = moments(tensor1d(e)), r = t.mean, n = t.variance, a = r.arraySync(), i = Math.sqrt(n.arraySync()), o = Array.from(e).map(function(e2) {
      return (e2 - a) / (i + EPSILON);
    });
    return new Float32Array(o);
  });
}
function getAudioContextConstructor() {
  return window.AudioContext || window.webkitAudioContext;
}
function getAudioMediaStream(e) {
  return __awaiter(this, void 0, void 0, function() {
    return __generator(this, function(t) {
      return [2, navigator.mediaDevices.getUserMedia({ audio: null == e || e, video: false })];
    });
  });
}
function playRawAudio(e, t) {
  var r = new (window.AudioContext || window.webkitAudioContext)(), n = r.createBuffer(1, e.data.length, e.sampleRateHz);
  n.getChannelData(0).set(e.data);
  var a = r.createBufferSource();
  a.buffer = n, a.connect(r.destination), a.start(), a.onended = function() {
    null != t && t();
  };
}
var BrowserFftFeatureExtractor = function() {
  function e(e2) {
    var t = this;
    if (null == e2) throw new Error("Required configuration object is missing for BrowserFftFeatureExtractor constructor");
    if (null == e2.spectrogramCallback) throw new Error("spectrogramCallback cannot be null or undefined");
    if (!(e2.numFramesPerSpectrogram > 0)) throw new Error("Invalid value in numFramesPerSpectrogram: " + e2.numFramesPerSpectrogram);
    if (e2.suppressionTimeMillis < 0) throw new Error("Expected suppressionTimeMillis to be >= 0, but got " + e2.suppressionTimeMillis);
    if (this.suppressionTimeMillis = e2.suppressionTimeMillis, this.spectrogramCallback = e2.spectrogramCallback, this.numFrames = e2.numFramesPerSpectrogram, this.sampleRateHz = e2.sampleRateHz || 44100, this.fftSize = e2.fftSize || 1024, this.frameDurationMillis = this.fftSize / this.sampleRateHz * 1e3, this.columnTruncateLength = e2.columnTruncateLength || this.fftSize, this.overlapFactor = e2.overlapFactor, this.includeRawAudio = e2.includeRawAudio, util_exports.assert(this.overlapFactor >= 0 && this.overlapFactor < 1, function() {
      return "Expected overlapFactor to be >= 0 and < 1, but got " + t.overlapFactor;
    }), this.columnTruncateLength > this.fftSize) throw new Error("columnTruncateLength " + this.columnTruncateLength + " exceeds fftSize (" + this.fftSize + ").");
    this.audioContextConstructor = getAudioContextConstructor();
  }
  return e.prototype.start = function(e2) {
    return __awaiter(this, void 0, void 0, function() {
      var t, r, n;
      return __generator(this, function(a) {
        switch (a.label) {
          case 0:
            if (null != this.frameIntervalTask) throw new Error("Cannot start already-started BrowserFftFeatureExtractor");
            return t = this, [4, getAudioMediaStream(e2)];
          case 1:
            return t.stream = a.sent(), this.audioContext = new this.audioContextConstructor({ sampleRate: this.sampleRateHz }), r = this.audioContext.createMediaStreamSource(this.stream), this.analyser = this.audioContext.createAnalyser(), this.analyser.fftSize = 2 * this.fftSize, this.analyser.smoothingTimeConstant = 0, r.connect(this.analyser), this.freqDataQueue = [], this.freqData = new Float32Array(this.fftSize), this.includeRawAudio && (this.timeDataQueue = [], this.timeData = new Float32Array(this.fftSize)), n = Math.max(1, Math.round(this.numFrames * (1 - this.overlapFactor))), this.tracker = new Tracker(n, Math.round(this.suppressionTimeMillis / this.frameDurationMillis)), this.frameIntervalTask = setInterval(this.onAudioFrame.bind(this), this.fftSize / this.sampleRateHz * 1e3), [2];
        }
      });
    });
  }, e.prototype.onAudioFrame = function() {
    return __awaiter(this, void 0, void 0, function() {
      var e2, t, r, n;
      return __generator(this, function(a) {
        switch (a.label) {
          case 0:
            return this.analyser.getFloatFrequencyData(this.freqData), this.freqData[0] === -1 / 0 ? [2] : (this.freqDataQueue.push(this.freqData.slice(0, this.columnTruncateLength)), this.includeRawAudio && (this.analyser.getFloatTimeDomainData(this.timeData), this.timeDataQueue.push(this.timeData.slice())), this.freqDataQueue.length > this.numFrames && this.freqDataQueue.shift(), this.tracker.tick() ? (e2 = flattenQueue(this.freqDataQueue), t = getInputTensorFromFrequencyData(e2, [1, this.numFrames, this.columnTruncateLength, 1]), r = void 0, this.includeRawAudio && (n = flattenQueue(this.timeDataQueue), r = getInputTensorFromFrequencyData(n, [1, this.numFrames * this.fftSize])), [4, this.spectrogramCallback(t, r)]) : [3, 2]);
          case 1:
            a.sent() && this.tracker.suppress(), dispose([t, r]), a.label = 2;
          case 2:
            return [2];
        }
      });
    });
  }, e.prototype.stop = function() {
    return __awaiter(this, void 0, void 0, function() {
      return __generator(this, function(e2) {
        if (null == this.frameIntervalTask) throw new Error("Cannot stop because there is no ongoing streaming activity.");
        return clearInterval(this.frameIntervalTask), this.frameIntervalTask = null, this.analyser.disconnect(), this.audioContext.close(), null != this.stream && this.stream.getTracks().length > 0 && this.stream.getTracks()[0].stop(), [2];
      });
    });
  }, e.prototype.setConfig = function(e2) {
    throw new Error("setConfig() is not implemented for BrowserFftFeatureExtractor.");
  }, e.prototype.getFeatures = function() {
    throw new Error("getFeatures() is not implemented for BrowserFftFeatureExtractor. Use the spectrogramCallback field of the constructor config instead.");
  }, e;
}();
function flattenQueue(e) {
  var t = e[0].length, r = new Float32Array(e.length * t);
  return e.forEach(function(e2, n) {
    return r.set(e2, n * t);
  }), r;
}
function getInputTensorFromFrequencyData(e, t) {
  var r = new Float32Array(util_exports.sizeFromShape(t));
  return r.set(e, r.length - e.length), tensor(r, t);
}
var Tracker = function() {
  function e(e2, t) {
    var r = this;
    this.period = e2, this.suppressionTime = null == t ? 0 : t, this.counter = 0, util_exports.assert(this.period > 0, function() {
      return "Expected period to be positive, but got " + r.period;
    });
  }
  return e.prototype.tick = function() {
    return this.counter++, this.counter % this.period == 0 && (null == this.suppressionOnset || this.counter - this.suppressionOnset > this.suppressionTime);
  }, e.prototype.suppress = function() {
    this.suppressionOnset = this.counter;
  }, e;
}();
function concatenateArrayBuffers(e) {
  var t = 0;
  e.forEach(function(e2) {
    t += e2.byteLength;
  });
  var r = new Uint8Array(t), n = 0;
  return e.forEach(function(e2) {
    r.set(new Uint8Array(e2), n), n += e2.byteLength;
  }), r.buffer;
}
function concatenateFloat32Arrays(e) {
  var t = 0;
  e.forEach(function(e2) {
    return t += e2.length;
  });
  var r = new Float32Array(t), n = 0;
  return e.forEach(function(e2) {
    r.set(e2, n), n += e2.length;
  }), r;
}
function string2ArrayBuffer(e) {
  if (null == e) throw new Error("Received null or undefind string");
  for (var t = unescape(encodeURIComponent(e)), r = new Uint8Array(t.length), n = 0; n < t.length; ++n) r[n] = t.charCodeAt(n);
  return r.buffer;
}
function arrayBuffer2String(e) {
  if (null == e) throw new Error("Received null or undefind buffer");
  var t = new Uint8Array(e);
  return decodeURIComponent(escape(String.fromCharCode.apply(String, __spread(t))));
}
function getUID() {
  function e() {
    return Math.floor(65536 * (1 + Math.random())).toString(16).substring(1);
  }
  return e() + e() + "-" + e() + "-" + e() + "-" + e() + "-" + e() + e() + e();
}
function getRandomInteger(e, t) {
  return Math.floor((t - e) * Math.random()) + e;
}
function balancedTrainValSplit(e, t, r) {
  return util_exports.assert(r > 0 && r < 1, function() {
    return "validationSplit is expected to be >0 and <1, but got " + r;
  }), tidy(function() {
    for (var n = argMax(t, -1).dataSync(), a = [], i = 0; i < n.length; ++i) {
      var o = n[i];
      null == a[o] && (a[o] = []), a[o].push(i);
    }
    var s = a.length, l = [], u = [];
    a.map(function(e2) {
      return util_exports.shuffle(e2);
    });
    for (i = 0; i < s; ++i) for (var c = a[i], h = Math.round(c.length * (1 - r)), d = 0; d < c.length; ++d) d < h ? l.push(c[d]) : u.push(c[d]);
    return { trainXs: gather(e, l), trainYs: gather(t, l), valXs: gather(e, u), valYs: gather(t, u) };
  });
}
function balancedTrainValSplitNumArrays(e, t, r) {
  var n, a, i, o, s, l, u, c;
  util_exports.assert(r > 0 && r < 1, function() {
    return "validationSplit is expected to be >0 and <1, but got " + r;
  });
  for (var h = !Array.isArray(e[0]), d = t, p = [], f = 0; f < d.length; ++f) {
    var m = d[f];
    null == p[m] && (p[m] = []), p[m].push(f);
  }
  var g = p.length, v = [], y = [];
  p.map(function(e2) {
    return util_exports.shuffle(e2);
  });
  for (f = 0; f < g; ++f) for (var w = p[f], b = Math.round(w.length * (1 - r)), _ = 0; _ < w.length; ++_) _ < b ? v.push(w[_]) : y.push(w[_]);
  if (h) {
    var S = [], E = [], x = [], A = [];
    try {
      for (var T = __values(v), I = T.next(); !I.done; I = T.next()) {
        var D = I.value;
        S.push(e[D]), E.push(t[D]);
      }
    } catch (e2) {
      n = { error: e2 };
    } finally {
      try {
        I && !I.done && (a = T.return) && a.call(T);
      } finally {
        if (n) throw n.error;
      }
    }
    try {
      for (var F = __values(y), O = F.next(); !O.done; O = F.next()) {
        D = O.value;
        x.push(e[D]), A.push(t[D]);
      }
    } catch (e2) {
      i = { error: e2 };
    } finally {
      try {
        O && !O.done && (o = F.return) && o.call(F);
      } finally {
        if (i) throw i.error;
      }
    }
    return { trainXs: S, trainYs: E, valXs: x, valYs: A };
  }
  S = [], E = [], x = [], A = [];
  try {
    for (var M = __values(v), z = M.next(); !z.done; z = M.next()) {
      D = z.value;
      S.push(e[D]), E.push(t[D]);
    }
  } catch (e2) {
    s = { error: e2 };
  } finally {
    try {
      z && !z.done && (l = M.return) && l.call(M);
    } finally {
      if (s) throw s.error;
    }
  }
  try {
    for (var R = __values(y), L = R.next(); !L.done; L = R.next()) {
      D = L.value;
      x.push(e[D]), A.push(t[D]);
    }
  } catch (e2) {
    u = { error: e2 };
  } finally {
    try {
      L && !L.done && (c = R.return) && c.call(R);
    } finally {
      if (u) throw u.error;
    }
  }
  return { trainXs: S, trainYs: E, valXs: x, valYs: A };
}
var DATASET_SERIALIZATION_DESCRIPTOR = "TFJSSCDS";
var DATASET_SERIALIZATION_VERSION = 1;
var BACKGROUND_NOISE_TAG = "_background_noise_";
var Dataset = function() {
  function e(e2) {
    if (this.examples = {}, this.label2Ids = {}, null != e2) for (var t = arrayBuffer2SerializedExamples(e2), r = 0, n = 0; n < t.manifest.length; ++n) {
      var a = t.manifest[n], i = a.spectrogramNumFrames * a.spectrogramFrameSize;
      null != a.rawAudioNumSamples && (i += a.rawAudioNumSamples), i *= 4, this.addExample(deserializeExample({ spec: a, data: t.data.slice(r, r + i) })), r += i;
    }
  }
  return e.prototype.addExample = function(e2) {
    util_exports.assert(null != e2, function() {
      return "Got null or undefined example";
    }), util_exports.assert(null != e2.label && e2.label.length > 0, function() {
      return "Expected label to be a non-empty string, but got " + JSON.stringify(e2.label);
    });
    var t = getUID();
    return this.examples[t] = e2, e2.label in this.label2Ids || (this.label2Ids[e2.label] = []), this.label2Ids[e2.label].push(t), t;
  }, e.prototype.merge = function(e2) {
    var t, r, n, a;
    util_exports.assert(e2 !== this, function() {
      return "Cannot merge a dataset into itself";
    });
    var i = e2.getVocabulary();
    try {
      for (var o = __values(i), s = o.next(); !s.done; s = o.next()) {
        var l = s.value, u = e2.getExamples(l);
        try {
          for (var c = (n = void 0, __values(u)), h = c.next(); !h.done; h = c.next()) {
            var d = h.value;
            this.addExample(d.example);
          }
        } catch (e3) {
          n = { error: e3 };
        } finally {
          try {
            h && !h.done && (a = c.return) && a.call(c);
          } finally {
            if (n) throw n.error;
          }
        }
      }
    } catch (e3) {
      t = { error: e3 };
    } finally {
      try {
        s && !s.done && (r = o.return) && r.call(o);
      } finally {
        if (t) throw t.error;
      }
    }
  }, e.prototype.getExampleCounts = function() {
    var e2 = {};
    for (var t in this.examples) {
      var r = this.examples[t];
      r.label in e2 || (e2[r.label] = 0), e2[r.label]++;
    }
    return e2;
  }, e.prototype.getExamples = function(e2) {
    var t = this;
    util_exports.assert(null != e2, function() {
      return "Expected label to be a string, but got " + JSON.stringify(e2);
    }), util_exports.assert(e2 in this.label2Ids, function() {
      return 'No example of label "' + e2 + '" exists in dataset';
    });
    var r = [];
    return this.label2Ids[e2].forEach(function(e3) {
      r.push({ uid: e3, example: t.examples[e3] });
    }), r;
  }, e.prototype.getData = function(e2, t) {
    var r = this;
    util_exports.assert(this.size() > 0, function() {
      return "Cannot get spectrograms as tensors because the dataset is empty";
    });
    var n = this.getVocabulary();
    null != e2 ? util_exports.assert(-1 !== n.indexOf(e2), function() {
      return "Label " + e2 + " is not in the vocabulary (" + JSON.stringify(n) + ")";
    }) : util_exports.assert(n.length > 1, function() {
      return "One-hot encoding of labels requires the vocabulary to have at least two words, but it has only " + n.length + " word.";
    }), null == t && (t = {});
    var a, i, o = this.getSortedUniqueNumFrames();
    1 === o.length ? (a = null == t.numFrames ? o[0] : t.numFrames, i = null == t.hopFrames ? 1 : t.hopFrames) : (a = t.numFrames, util_exports.assert(null != a && Number.isInteger(a) && a > 0, function() {
      return "There are " + o.length + " unique lengths among the " + r.size() + " examples of this Dataset, hence numFrames is required. But it is not provided.";
    }), util_exports.assert(a <= o[0], function() {
      return "numFrames (" + a + ") exceeds the minimum numFrames (" + o[0] + ") among the examples of the Dataset.";
    }), i = t.hopFrames, util_exports.assert(null != i && Number.isInteger(i) && i > 0, function() {
      return "There are " + o.length + " unique lengths among the " + r.size() + " examples of this Dataset, hence hopFrames is required. But it is not provided.";
    }));
    var s = null == t.normalize || t.normalize;
    return tidy(function() {
      for (var o2, l, u, c = [], h = [], d = [], p = 0; p < n.length; ++p) {
        var f = n[p];
        if (null == e2 || f === e2) {
          var m = r.label2Ids[f], g = function(n2) {
            var o3, l2, m2 = r.examples[n2].spectrogram, g2 = m2.frameSize;
            null == u ? u = g2 : util_exports.assert(g2 === u, function() {
              return "Mismatch in frameSize  (" + g2 + " vs " + u + ")";
            });
            var v2 = m2.data.length / g2, y2 = null;
            f !== BACKGROUND_NOISE_TAG && (y2 = null == m2.keyFrameIndex ? getMaxIntensityFrameIndex(m2).dataSync()[0] : m2.keyFrameIndex);
            var w2 = tensor3d(m2.data, [v2, g2, 1]), b2 = getValidWindows(v2, y2, a, i), _2 = function(r2) {
              var n3 = tidy(function() {
                var e3 = slice(w2, [r2[0], 0, 0], [r2[1] - r2[0], -1, -1]);
                return s ? normalize(e3) : e3;
              });
              t.getDataset ? h.push(n3.dataSync()) : c.push(n3), null == e2 && d.push(p);
            };
            try {
              for (var S2 = (o3 = void 0, __values(b2)), E2 = S2.next(); !E2.done; E2 = S2.next()) {
                _2(E2.value);
              }
            } catch (e3) {
              o3 = { error: e3 };
            } finally {
              try {
                E2 && !E2.done && (l2 = S2.return) && l2.call(S2);
              } finally {
                if (o3) throw o3.error;
              }
            }
            dispose(w2);
          };
          try {
            for (var v = (o2 = void 0, __values(m)), y = v.next(); !y.done; y = v.next()) {
              g(y.value);
            }
          } catch (e3) {
            o2 = { error: e3 };
          } finally {
            try {
              y && !y.done && (l = v.return) && l.call(v);
            } finally {
              if (o2) throw o2.error;
            }
          }
        }
      }
      null != t.augmentByMixingNoiseRatio && r.augmentByMixingNoise(t.getDataset ? h : c, d, t.augmentByMixingNoiseRatio);
      var w = null == t.shuffle || t.shuffle;
      if (t.getDataset) {
        var b = null == t.datasetBatchSize ? 32 : t.datasetBatchSize, _ = null == t.datasetValidationSplit ? 0.15 : t.datasetValidationSplit;
        util_exports.assert(_ > 0 && _ < 1, function() {
          return "Invalid dataset validation split: " + _;
        });
        var S = h.map(function(e3, t2) {
          return [e3, d[t2]];
        });
        util_exports.shuffle(S), h = S.map(function(e3) {
          return e3[0];
        });
        var E = S.map(function(e3) {
          return e3[1];
        }), x = balancedTrainValSplitNumArrays(h, E, _), A = x.trainXs, T = x.trainYs, I = x.valXs, D = x.valYs, F = array(A).map(function(e3) {
          return tensor3d(e3, [a, u, 1]);
        }), O = array(T).map(function(e3) {
          return squeeze(oneHot([e3], n.length), [0]);
        }), M = zip({ xs: F, ys: O });
        w && (M = M.shuffle(h.length)), M = M.batch(b).prefetch(4);
        var z = array(I).map(function(e3) {
          return tensor3d(e3, [a, u, 1]);
        }), R = array(D).map(function(e3) {
          return squeeze(oneHot([e3], n.length), [0]);
        }), L = zip({ xs: z, ys: R });
        return [M, L = L.batch(b).prefetch(4)];
      }
      if (w) {
        var N = [];
        c.forEach(function(e3, t2) {
          N.push({ x: e3, y: d[t2] });
        }), util_exports.shuffle(N), c = N.map(function(e3) {
          return e3.x;
        }), d = N.map(function(e3) {
          return e3.y;
        });
      }
      var C = null == e2 ? cast(oneHot(tensor1d(d, "int32"), n.length), "float32") : void 0;
      return { xs: stack(c), ys: C };
    });
  }, e.prototype.augmentByMixingNoise = function(e2, t, r) {
    var n, a;
    if (null == e2 || 0 === e2.length) throw new Error("Cannot perform augmentation because data is null or empty");
    for (var i = e2[0] instanceof Float32Array, o = this.getVocabulary(), s = [], l = [], u = 0; u < t.length; ++u) o[t[u]] === BACKGROUND_NOISE_TAG ? s.push(u) : l.push(u);
    if (0 === s.length) throw new Error("Cannot perform augmentation by mixing with noise when there is no example with label " + BACKGROUND_NOISE_TAG);
    var c = [], h = [], d = function(n2) {
      var a2 = s[getRandomInteger(0, s.length)], o2 = i ? tensor1d(e2[n2]) : e2[n2], l2 = i ? tensor1d(e2[a2]) : e2[a2], u2 = tidy(function() {
        return normalize(add(o2, mul(l2, r)));
      });
      i ? c.push(u2.dataSync()) : c.push(u2), h.push(t[n2]);
    };
    try {
      for (var p = __values(l), f = p.next(); !f.done; f = p.next()) {
        d(f.value);
      }
    } catch (e3) {
      n = { error: e3 };
    } finally {
      try {
        f && !f.done && (a = p.return) && a.call(p);
      } finally {
        if (n) throw n.error;
      }
    }
    console.log("Data augmentation: mixing noise: added " + c.length + " examples"), c.forEach(function(t2) {
      return e2.push(t2);
    }), t.push.apply(t, __spread(h));
  }, e.prototype.getSortedUniqueNumFrames = function() {
    for (var e2, t, r = /* @__PURE__ */ new Set(), n = this.getVocabulary(), a = 0; a < n.length; ++a) {
      var i = n[a], o = this.label2Ids[i];
      try {
        for (var s = (e2 = void 0, __values(o)), l = s.next(); !l.done; l = s.next()) {
          var u = l.value, c = this.examples[u].spectrogram, h = c.data.length / c.frameSize;
          r.add(h);
        }
      } catch (t2) {
        e2 = { error: t2 };
      } finally {
        try {
          l && !l.done && (t = s.return) && t.call(s);
        } finally {
          if (e2) throw e2.error;
        }
      }
    }
    var d = __spread(r);
    return d.sort(), d;
  }, e.prototype.removeExample = function(e2) {
    if (!(e2 in this.examples)) throw new Error("Nonexistent example UID: " + e2);
    var t = this.examples[e2].label;
    delete this.examples[e2];
    var r = this.label2Ids[t].indexOf(e2);
    this.label2Ids[t].splice(r, 1), 0 === this.label2Ids[t].length && delete this.label2Ids[t];
  }, e.prototype.setExampleKeyFrameIndex = function(e2, t) {
    if (!(e2 in this.examples)) throw new Error("Nonexistent example UID: " + e2);
    var r = this.examples[e2].spectrogram, n = r.data.length / r.frameSize;
    util_exports.assert(t >= 0 && t < n && Number.isInteger(t), function() {
      return "Invalid keyFrameIndex: " + t + ". Must be >= 0, < " + n + ", and an integer.";
    }), r.keyFrameIndex = t;
  }, e.prototype.size = function() {
    return Object.keys(this.examples).length;
  }, e.prototype.durationMillis = function() {
    var e2 = 0;
    for (var t in this.examples) {
      var r = this.examples[t].spectrogram, n = 23.22 | r.frameDurationMillis;
      e2 += r.data.length / r.frameSize * n;
    }
    return e2;
  }, e.prototype.empty = function() {
    return 0 === this.size();
  }, e.prototype.clear = function() {
    this.examples = {};
  }, e.prototype.getVocabulary = function() {
    var e2 = /* @__PURE__ */ new Set();
    for (var t in this.examples) {
      var r = this.examples[t];
      e2.add(r.label);
    }
    var n = __spread(e2);
    return n.sort(), n;
  }, e.prototype.serialize = function(e2) {
    var t, r, n, a, i = this.getVocabulary();
    util_exports.assert(!this.empty(), function() {
      return "Cannot serialize empty Dataset";
    }), null != e2 && (Array.isArray(e2) || (e2 = [e2]), e2.forEach(function(e3) {
      if (-1 === i.indexOf(e3)) throw new Error('Word label "' + e3 + '" does not exist in the vocabulary of this dataset. The vocabulary is: ' + JSON.stringify(i) + ".");
    }));
    var o = [], s = [];
    try {
      for (var l = __values(i), u = l.next(); !u.done; u = l.next()) {
        var c = u.value;
        if (null == e2 || -1 !== e2.indexOf(c)) {
          var h = this.label2Ids[c];
          try {
            for (var d = (n = void 0, __values(h)), p = d.next(); !p.done; p = d.next()) {
              var f = p.value, m = serializeExample(this.examples[f]);
              o.push(m.spec), s.push(m.data);
            }
          } catch (e3) {
            n = { error: e3 };
          } finally {
            try {
              p && !p.done && (a = d.return) && a.call(d);
            } finally {
              if (n) throw n.error;
            }
          }
        }
      }
    } catch (e3) {
      t = { error: e3 };
    } finally {
      try {
        u && !u.done && (r = l.return) && r.call(l);
      } finally {
        if (t) throw t.error;
      }
    }
    return serializedExamples2ArrayBuffer({ manifest: o, data: concatenateArrayBuffers(s) });
  }, e;
}();
function serializeExample(e) {
  var t = null != e.rawAudio, r = { label: e.label, spectrogramNumFrames: e.spectrogram.data.length / e.spectrogram.frameSize, spectrogramFrameSize: e.spectrogram.frameSize };
  null != e.spectrogram.keyFrameIndex && (r.spectrogramKeyFrameIndex = e.spectrogram.keyFrameIndex);
  var n = e.spectrogram.data.buffer.slice(0);
  return t && (r.rawAudioNumSamples = e.rawAudio.data.length, r.rawAudioSampleRateHz = e.rawAudio.sampleRateHz, n = concatenateArrayBuffers([n, e.rawAudio.data.buffer])), { spec: r, data: n };
}
function deserializeExample(e) {
  var t = { frameSize: e.spec.spectrogramFrameSize, data: new Float32Array(e.data.slice(0, 4 * e.spec.spectrogramFrameSize * e.spec.spectrogramNumFrames)) };
  null != e.spec.spectrogramKeyFrameIndex && (t.keyFrameIndex = e.spec.spectrogramKeyFrameIndex);
  var r = { label: e.spec.label, spectrogram: t };
  return null != e.spec.rawAudioNumSamples && (r.rawAudio = { sampleRateHz: e.spec.rawAudioSampleRateHz, data: new Float32Array(e.data.slice(4 * e.spec.spectrogramFrameSize * e.spec.spectrogramNumFrames)) }), r;
}
function serializedExamples2ArrayBuffer(e) {
  var t = string2ArrayBuffer(JSON.stringify(e.manifest)), r = string2ArrayBuffer(DATASET_SERIALIZATION_DESCRIPTOR), n = new Uint32Array([DATASET_SERIALIZATION_VERSION]), a = new Uint32Array([t.byteLength]);
  return concatenateArrayBuffers([concatenateArrayBuffers([r, n.buffer, a.buffer]), t, e.data]);
}
function arrayBuffer2SerializedExamples(e) {
  util_exports.assert(null != e, function() {
    return "Received null or undefined buffer";
  });
  var t = 0, r = arrayBuffer2String(e.slice(t, DATASET_SERIALIZATION_DESCRIPTOR.length));
  util_exports.assert(r === DATASET_SERIALIZATION_DESCRIPTOR, function() {
    return "Deserialization error: Invalid descriptor";
  }), t += DATASET_SERIALIZATION_DESCRIPTOR.length, t += 4;
  var n = new Uint32Array(e, t, 1), a = t += 4;
  t = a + n[0];
  var i = arrayBuffer2String(e.slice(a, t));
  return { manifest: JSON.parse(i), data: e.slice(t) };
}
function getValidWindows(e, t, r, n) {
  if (util_exports.assert(Number.isInteger(e) && e > 0, function() {
    return "snippetLength must be a positive integer, but got " + e;
  }), null != t && util_exports.assert(Number.isInteger(t) && t >= 0, function() {
    return "focusIndex must be a non-negative integer, but got " + t;
  }), util_exports.assert(Number.isInteger(r) && r > 0, function() {
    return "windowLength must be a positive integer, but got " + r;
  }), util_exports.assert(Number.isInteger(n) && n > 0, function() {
    return "windowHop must be a positive integer, but got " + n;
  }), util_exports.assert(r <= e, function() {
    return "windowLength (" + r + ") exceeds snippetLength (" + e + ")";
  }), util_exports.assert(t < e, function() {
    return "focusIndex (" + t + ") equals or exceeds snippetLength (" + e + ")";
  }), r === e) return [[0, e]];
  var a = [];
  if (null == t) {
    for (var i = 0; i + r <= e; ) a.push([i, i + r]), i += n;
    return a;
  }
  var o = Math.floor(r / 2), s = t - o;
  for (s < 0 ? s = 0 : s + r > e && (s = e - r); !(s - n < 0 || t >= s - n + r); ) s -= n;
  for (; s + r <= e && !(t < s); ) a.push([s, s + r]), s += n;
  return a;
}
function spectrogram2IntensityCurve(e) {
  return tidy(function() {
    var t = e.data.length / e.frameSize, r = tensor2d(e.data, [t, e.frameSize]);
    return mean(r, -1);
  });
}
function getMaxIntensityFrameIndex(e) {
  return tidy(function() {
    return argMax(spectrogram2IntensityCurve(e));
  });
}
var version = "0.5.4";
var UNKNOWN_TAG = "_unknown_";
var SAVED_MODEL_METADATA_KEY = "tfjs-speech-commands-saved-model-metadata";
var SAVE_PATH_PREFIX = "indexeddb://tfjs-speech-commands-model/";
var localStorageWrapper = { localStorage: "undefined" == typeof window ? null : window.localStorage };
function getMajorAndMinorVersion(e) {
  return e.split(".").slice(0, 2).join(".");
}
var DEFAULT_WINDOW_HOP_RATIO = 0.25;
var BrowserFftSpeechCommandRecognizer = function() {
  function e(t, r, n) {
    this.MODEL_URL_PREFIX = "https://storage.googleapis.com/tfjs-models/tfjs/speech-commands/v" + getMajorAndMinorVersion(version) + "/browser_fft", this.SAMPLE_RATE_HZ = 44100, this.FFT_SIZE = 1024, this.DEFAULT_SUPPRESSION_TIME_MILLIS = 0, this.streaming = false, this.transferRecognizers = {}, util_exports.assert(null == r && null == n || null != r && null != n, function() {
      return "modelURL and metadataURL must be both provided or both not provided.";
    }), null == r ? (null == t ? t = e.DEFAULT_VOCABULARY_NAME : util_exports.assert(-1 !== e.VALID_VOCABULARY_NAMES.indexOf(t), function() {
      return "Invalid vocabulary name: '" + t + "'";
    }), this.vocabulary = t, this.modelArtifactsOrURL = this.MODEL_URL_PREFIX + "/" + this.vocabulary + "/model.json", this.metadataOrURL = this.MODEL_URL_PREFIX + "/" + this.vocabulary + "/metadata.json") : (util_exports.assert(null == t, function() {
      return "vocabulary name must be null or undefined when modelURL is provided";
    }), this.modelArtifactsOrURL = r, this.metadataOrURL = n), this.parameters = { sampleRateHz: this.SAMPLE_RATE_HZ, fftSize: this.FFT_SIZE };
  }
  return e.prototype.listen = function(e2, t) {
    return __awaiter(this, void 0, void 0, function() {
      var r, n, a, i, o, s = this;
      return __generator(this, function(l) {
        switch (l.label) {
          case 0:
            if (this.streaming) throw new Error("Cannot start streaming again when streaming is ongoing.");
            return [4, this.ensureModelLoaded()];
          case 1:
            if (l.sent(), null == t && (t = {}), r = null == t.probabilityThreshold ? 0 : t.probabilityThreshold, t.includeEmbedding && (r = 0), util_exports.assert(r >= 0 && r <= 1, function() {
              return "Invalid probabilityThreshold value: " + r;
            }), n = null != t.invokeCallbackOnNoiseAndUnknown && t.invokeCallbackOnNoiseAndUnknown, t.includeEmbedding && (n = true), t.suppressionTimeMillis < 0) throw new Error("suppressionTimeMillis is expected to be >= 0, but got " + t.suppressionTimeMillis);
            return a = null == t.overlapFactor ? 0.5 : t.overlapFactor, util_exports.assert(a >= 0 && a < 1, function() {
              return "Expected overlapFactor to be >= 0 and < 1, but got " + a;
            }), i = function(a2, i2) {
              return __awaiter(s, void 0, void 0, function() {
                var i3, o2, s2, l2, u, c, h, d, p, f, m;
                return __generator(this, function(g) {
                  switch (g.label) {
                    case 0:
                      return i3 = normalize(a2), t.includeEmbedding ? [4, this.ensureModelWithEmbeddingOutputCreated()] : [3, 2];
                    case 1:
                      return g.sent(), m = __read(this.modelWithEmbeddingOutput.predict(i3), 2), o2 = m[0], s2 = m[1], [3, 3];
                    case 2:
                      o2 = this.model.predict(i3), g.label = 3;
                    case 3:
                      return [4, o2.data()];
                    case 4:
                      return l2 = g.sent(), [4, (u = o2.argMax(-1)).data()];
                    case 5:
                      return c = g.sent()[0], h = Math.max.apply(Math, __spread(l2)), dispose([o2, u, i3]), h < r ? [2, false] : [3, 6];
                    case 6:
                      return d = void 0, t.includeSpectrogram ? (p = {}, [4, a2.data()]) : [3, 8];
                    case 7:
                      p.data = g.sent(), p.frameSize = this.nonBatchInputShape[1], d = p, g.label = 8;
                    case 8:
                      return f = true, n || this.words[c] !== BACKGROUND_NOISE_TAG && this.words[c] !== UNKNOWN_TAG || (f = false), f && e2({ scores: l2, spectrogram: d, embedding: s2 }), [2, f];
                  }
                });
              });
            }, o = null == t.suppressionTimeMillis ? this.DEFAULT_SUPPRESSION_TIME_MILLIS : t.suppressionTimeMillis, this.audioDataExtractor = new BrowserFftFeatureExtractor({ sampleRateHz: this.parameters.sampleRateHz, numFramesPerSpectrogram: this.nonBatchInputShape[0], columnTruncateLength: this.nonBatchInputShape[1], suppressionTimeMillis: o, spectrogramCallback: i, overlapFactor: a }), [4, this.audioDataExtractor.start(t.audioTrackConstraints)];
          case 2:
            return l.sent(), this.streaming = true, [2];
        }
      });
    });
  }, e.prototype.ensureModelLoaded = function() {
    return __awaiter(this, void 0, void 0, function() {
      var e2, t, r, n, a = this;
      return __generator(this, function(i) {
        switch (i.label) {
          case 0:
            return null != this.model ? [2] : [4, this.ensureMetadataLoaded()];
          case 1:
            return i.sent(), "string" != typeof this.modelArtifactsOrURL ? [3, 3] : [4, loadLayersModel(this.modelArtifactsOrURL)];
          case 2:
            return e2 = i.sent(), [3, 5];
          case 3:
            return [4, loadLayersModel(io_exports.fromMemory(this.modelArtifactsOrURL.modelTopology, this.modelArtifactsOrURL.weightSpecs, this.modelArtifactsOrURL.weightData))];
          case 4:
            e2 = i.sent(), i.label = 5;
          case 5:
            if (1 !== e2.inputs.length) throw new Error("Expected model to have 1 input, but got a model with " + e2.inputs.length + " inputs");
            if (4 !== e2.inputs[0].shape.length) throw new Error("Expected model to have an input shape of rank 4, but got an input shape of rank " + e2.inputs[0].shape.length);
            if (1 !== e2.inputs[0].shape[3]) throw new Error("Expected model to have an input shape with 1 as the last dimension, but got input shape" + JSON.stringify(e2.inputs[0].shape[3]) + "}");
            if (2 !== (t = e2.outputShape).length) throw new Error("Expected loaded model to have an output shape of rank 2,but received shape " + JSON.stringify(t));
            if (t[1] !== this.words.length) throw new Error("Mismatch between the last dimension of model's output shape (" + t[1] + ") and number of words (" + this.words.length + ").");
            return this.model = e2, this.freezeModel(), this.nonBatchInputShape = e2.inputs[0].shape.slice(1), this.elementsPerExample = 1, e2.inputs[0].shape.slice(1).forEach(function(e3) {
              return a.elementsPerExample *= e3;
            }), this.warmUpModel(), r = this.parameters.fftSize / this.parameters.sampleRateHz * 1e3, n = e2.inputs[0].shape[1], this.parameters.spectrogramDurationMillis = n * r, [2];
        }
      });
    });
  }, e.prototype.ensureModelWithEmbeddingOutputCreated = function() {
    return __awaiter(this, void 0, void 0, function() {
      var e2, t;
      return __generator(this, function(r) {
        switch (r.label) {
          case 0:
            return null != this.modelWithEmbeddingOutput ? [2] : [4, this.ensureModelLoaded()];
          case 1:
            for (r.sent(), t = this.model.layers.length - 2; t >= 0; --t) if ("Dense" === this.model.layers[t].getClassName()) {
              e2 = this.model.layers[t];
              break;
            }
            if (null == e2) throw new Error("Failed to find second last dense layer in the original model.");
            return this.modelWithEmbeddingOutput = model({ inputs: this.model.inputs, outputs: [this.model.outputs[0], e2.output] }), [2];
        }
      });
    });
  }, e.prototype.warmUpModel = function() {
    var e2 = this;
    tidy(function() {
      for (var t = zeros([1].concat(e2.nonBatchInputShape)), r = 0; r < 3; ++r) e2.model.predict(t);
    });
  }, e.prototype.ensureMetadataLoaded = function() {
    return __awaiter(this, void 0, void 0, function() {
      var e2, t, r;
      return __generator(this, function(n) {
        switch (n.label) {
          case 0:
            return null != this.words ? [2] : "string" != typeof this.metadataOrURL ? [3, 2] : [4, loadMetadataJson(this.metadataOrURL)];
          case 1:
            return t = n.sent(), [3, 3];
          case 2:
            t = this.metadataOrURL, n.label = 3;
          case 3:
            if (null == (e2 = t).wordLabels) {
              if (null == (r = e2.words)) throw new Error('Cannot find field "words" or "wordLabels" in metadata JSON file');
              this.words = r;
            } else this.words = e2.wordLabels;
            return [2];
        }
      });
    });
  }, e.prototype.stopListening = function() {
    return __awaiter(this, void 0, void 0, function() {
      return __generator(this, function(e2) {
        switch (e2.label) {
          case 0:
            if (!this.streaming) throw new Error("Cannot stop streaming when streaming is not ongoing.");
            return [4, this.audioDataExtractor.stop()];
          case 1:
            return e2.sent(), this.streaming = false, [2];
        }
      });
    });
  }, e.prototype.isListening = function() {
    return this.streaming;
  }, e.prototype.wordLabels = function() {
    return this.words;
  }, e.prototype.params = function() {
    return this.parameters;
  }, e.prototype.modelInputShape = function() {
    if (null == this.model) throw new Error("Model has not been loaded yet. Load model by calling ensureModelLoaded(), recognize(), or listen().");
    return this.model.inputs[0].shape;
  }, e.prototype.recognize = function(e2, t) {
    return __awaiter(this, void 0, void 0, function() {
      var r, n, a, i, o, s, l, u, c, h, d, p, f;
      return __generator(this, function(m) {
        switch (m.label) {
          case 0:
            return null == t && (t = {}), [4, this.ensureModelLoaded()];
          case 1:
            return m.sent(), null != e2 ? [3, 3] : [4, this.recognizeOnline()];
          case 2:
            r = m.sent(), e2 = r.data, m.label = 3;
          case 3:
            if (e2 instanceof Tensor) this.checkInputTensorShape(e2), a = e2, n = e2.shape[0];
            else {
              if (e2.length % this.elementsPerExample) throw new Error("The length of the input Float32Array " + e2.length + " is not divisible by the number of tensor elements per per example expected by the model " + this.elementsPerExample + ".");
              n = e2.length / this.elementsPerExample, a = tensor4d(e2, [n].concat(this.nonBatchInputShape));
            }
            return o = { scores: null }, t.includeEmbedding ? [4, this.ensureModelWithEmbeddingOutputCreated()] : [3, 5];
          case 4:
            return m.sent(), s = this.modelWithEmbeddingOutput.predict(a), i = s[0], o.embedding = s[1], [3, 6];
          case 5:
            i = this.model.predict(a), m.label = 6;
          case 6:
            return 1 !== n ? [3, 8] : (l = o, [4, i.data()]);
          case 7:
            return l.scores = m.sent(), [3, 10];
          case 8:
            return u = unstack(i), c = u.map(function(e3) {
              return e3.data();
            }), h = o, [4, Promise.all(c)];
          case 9:
            h.scores = m.sent(), dispose(u), m.label = 10;
          case 10:
            return t.includeSpectrogram ? (d = o, p = {}, e2 instanceof Tensor ? [4, e2.data()] : [3, 12]) : [3, 14];
          case 11:
            return f = m.sent(), [3, 13];
          case 12:
            f = e2, m.label = 13;
          case 13:
            d.spectrogram = (p.data = f, p.frameSize = this.nonBatchInputShape[1], p), m.label = 14;
          case 14:
            return dispose(i), [2, o];
        }
      });
    });
  }, e.prototype.recognizeOnline = function() {
    return __awaiter(this, void 0, void 0, function() {
      var e2 = this;
      return __generator(this, function(t) {
        return [2, new Promise(function(t2, r) {
          e2.audioDataExtractor = new BrowserFftFeatureExtractor({ sampleRateHz: e2.parameters.sampleRateHz, numFramesPerSpectrogram: e2.nonBatchInputShape[0], columnTruncateLength: e2.nonBatchInputShape[1], suppressionTimeMillis: 0, spectrogramCallback: function(r2) {
            return __awaiter(e2, void 0, void 0, function() {
              var e3, n, a;
              return __generator(this, function(i) {
                switch (i.label) {
                  case 0:
                    return e3 = normalize(r2), [4, this.audioDataExtractor.stop()];
                  case 1:
                    return i.sent(), n = t2, a = {}, [4, e3.data()];
                  case 2:
                    return n.apply(void 0, [(a.data = i.sent(), a.frameSize = this.nonBatchInputShape[1], a)]), e3.dispose(), [2, false];
                }
              });
            });
          }, overlapFactor: 0 }), e2.audioDataExtractor.start();
        })];
      });
    });
  }, e.prototype.createTransfer = function(e2) {
    if (null == this.model) throw new Error("Model has not been loaded yet. Load model by calling ensureModelLoaded(), recognizer(), or listen().");
    util_exports.assert(null != e2 && "string" == typeof e2 && e2.length > 1, function() {
      return "Expected the name for a transfer-learning recognized to be a non-empty string, but got " + JSON.stringify(e2);
    }), util_exports.assert(null == this.transferRecognizers[e2], function() {
      return "There is already a transfer-learning model named '" + e2 + "'";
    });
    var t = new TransferBrowserFftSpeechCommandRecognizer(e2, this.parameters, this.model);
    return this.transferRecognizers[e2] = t, t;
  }, e.prototype.freezeModel = function() {
    var e2, t;
    try {
      for (var r = __values(this.model.layers), n = r.next(); !n.done; n = r.next()) {
        n.value.trainable = false;
      }
    } catch (t2) {
      e2 = { error: t2 };
    } finally {
      try {
        n && !n.done && (t = r.return) && t.call(r);
      } finally {
        if (e2) throw e2.error;
      }
    }
  }, e.prototype.checkInputTensorShape = function(e2) {
    var t = this.model.inputs[0].shape.length;
    if (e2.shape.length !== t) throw new Error("Expected input Tensor to have rank " + t + ", but got rank " + e2.shape.length + " that differs ");
    var r = e2.shape.slice(1), n = this.model.inputs[0].shape.slice(1);
    if (!util_exports.arraysEqual(r, n)) throw new Error("Expected input to have shape [null," + n + "], but got shape [null," + r + "]");
  }, e.VALID_VOCABULARY_NAMES = ["18w", "directional4w"], e.DEFAULT_VOCABULARY_NAME = "18w", e;
}();
var TransferBrowserFftSpeechCommandRecognizer = function(e) {
  function t(t2, r, n) {
    var a = e.call(this) || this;
    return a.name = t2, a.parameters = r, a.baseModel = n, util_exports.assert(null != t2 && "string" == typeof t2 && t2.length > 0, function() {
      return "The name of a transfer model must be a non-empty string, but got " + JSON.stringify(t2);
    }), a.nonBatchInputShape = a.baseModel.inputs[0].shape.slice(1), a.words = null, a.dataset = new Dataset(), a;
  }
  return __extends(t, e), t.prototype.collectExample = function(e2, t2) {
    return __awaiter(this, void 0, void 0, function() {
      var r, n, a, i, o = this;
      return __generator(this, function(s) {
        if (util_exports.assert(!this.streaming, function() {
          return "Cannot start collection of transfer-learning example because a streaming recognition or transfer-learning example collection is ongoing";
        }), util_exports.assert(null != e2 && "string" == typeof e2 && e2.length > 0, function() {
          return "Must provide a non-empty string when collecting transfer-learning example";
        }), null == t2 && (t2 = {}), null != t2.durationMultiplier && null != t2.durationSec) throw new Error("durationMultiplier and durationSec are mutually exclusive, but are both specified.");
        return null != t2.durationSec ? (util_exports.assert(t2.durationSec > 0, function() {
          return "Expected durationSec to be > 0, but got " + t2.durationSec;
        }), n = this.parameters.fftSize / this.parameters.sampleRateHz, r = Math.ceil(t2.durationSec / n)) : null != t2.durationMultiplier ? (util_exports.assert(t2.durationMultiplier >= 1, function() {
          return "Expected duration multiplier to be >= 1, but got " + t2.durationMultiplier;
        }), r = Math.round(this.nonBatchInputShape[0] * t2.durationMultiplier)) : r = this.nonBatchInputShape[0], null != t2.snippetDurationSec && (util_exports.assert(t2.snippetDurationSec > 0, function() {
          return "snippetDurationSec is expected to be > 0, but got " + t2.snippetDurationSec;
        }), util_exports.assert(null != t2.onSnippet, function() {
          return "onSnippet must be provided if snippetDurationSec is provided.";
        })), null != t2.onSnippet && util_exports.assert(null != t2.snippetDurationSec, function() {
          return "snippetDurationSec must be provided if onSnippet is provided.";
        }), a = this.parameters.fftSize / this.parameters.sampleRateHz, i = a * r, this.streaming = true, [2, new Promise(function(n2) {
          var a2 = null == t2.snippetDurationSec ? 1 : t2.snippetDurationSec / i, s2 = 1 - a2, l = Math.round(1 / a2), u = 0, c = -1, h = [];
          o.audioDataExtractor = new BrowserFftFeatureExtractor({ sampleRateHz: o.parameters.sampleRateHz, numFramesPerSpectrogram: r, columnTruncateLength: o.nonBatchInputShape[1], suppressionTimeMillis: 0, spectrogramCallback: function(r2, a3) {
            return __awaiter(o, void 0, void 0, function() {
              var i2, o2, s3, d, p, f, m, g, v, y, w, b, _, S, E, x, A, T, I, D;
              return __generator(this, function(F) {
                switch (F.label) {
                  case 0:
                    return null != t2.onSnippet ? [3, 7] : (i2 = normalize(r2), s3 = (o2 = this.dataset).addExample, d = { label: e2 }, p = {}, [4, i2.data()]);
                  case 1:
                    return d.spectrogram = (p.data = F.sent(), p.frameSize = this.nonBatchInputShape[1], p), t2.includeRawAudio ? (m = {}, [4, a3.data()]) : [3, 3];
                  case 2:
                    return m.data = F.sent(), m.sampleRateHz = this.audioDataExtractor.sampleRateHz, f = m, [3, 4];
                  case 3:
                    f = void 0, F.label = 4;
                  case 4:
                    return s3.apply(o2, [(d.rawAudio = f, d)]), i2.dispose(), [4, this.audioDataExtractor.stop()];
                  case 5:
                    return F.sent(), this.streaming = false, this.collateTransferWords(), g = n2, v = {}, [4, r2.data()];
                  case 6:
                    return g.apply(void 0, [(v.data = F.sent(), v.frameSize = this.nonBatchInputShape[1], v)]), [3, 13];
                  case 7:
                    return [4, r2.data()];
                  case 8:
                    for (y = F.sent(), -1 === c && (c = y.length), w = c - 1; 0 !== y[w] && w >= 0; ) w--;
                    return b = c - w - 1, c = w + 1, _ = y.slice(y.length - b, y.length), h.push(_), null != t2.onSnippet && t2.onSnippet({ data: _, frameSize: this.nonBatchInputShape[1] }), u++ !== l ? [3, 13] : [4, this.audioDataExtractor.stop()];
                  case 9:
                    return F.sent(), this.streaming = false, this.collateTransferWords(), S = normalizeFloat32Array(concatenateFloat32Arrays(h)), E = { data: S, frameSize: this.nonBatchInputShape[1] }, A = (x = this.dataset).addExample, T = { label: e2, spectrogram: E }, t2.includeRawAudio ? (D = {}, [4, a3.data()]) : [3, 11];
                  case 10:
                    return D.data = F.sent(), D.sampleRateHz = this.audioDataExtractor.sampleRateHz, I = D, [3, 12];
                  case 11:
                    I = void 0, F.label = 12;
                  case 12:
                    A.apply(x, [(T.rawAudio = I, T)]), n2(E), F.label = 13;
                  case 13:
                    return [2, false];
                }
              });
            });
          }, overlapFactor: s2, includeRawAudio: t2.includeRawAudio }), o.audioDataExtractor.start(t2.audioTrackConstraints);
        })];
      });
    });
  }, t.prototype.clearExamples = function() {
    var e2 = this;
    util_exports.assert(null != this.words && this.words.length > 0 && !this.dataset.empty(), function() {
      return "No transfer learning examples exist for model name " + e2.name;
    }), this.dataset.clear(), this.words = null;
  }, t.prototype.countExamples = function() {
    if (this.dataset.empty()) throw new Error("No examples have been collected for transfer-learning model named '" + this.name + "' yet.");
    return this.dataset.getExampleCounts();
  }, t.prototype.getExamples = function(e2) {
    return this.dataset.getExamples(e2);
  }, t.prototype.setExampleKeyFrameIndex = function(e2, t2) {
    this.dataset.setExampleKeyFrameIndex(e2, t2);
  }, t.prototype.removeExample = function(e2) {
    this.dataset.removeExample(e2), this.collateTransferWords();
  }, t.prototype.isDatasetEmpty = function() {
    return this.dataset.empty();
  }, t.prototype.loadExamples = function(e2, t2) {
    var r, n, a, i;
    void 0 === t2 && (t2 = false);
    var o = new Dataset(e2);
    t2 && this.clearExamples();
    var s = o.getVocabulary();
    try {
      for (var l = __values(s), u = l.next(); !u.done; u = l.next()) {
        var c = u.value, h = o.getExamples(c);
        try {
          for (var d = (a = void 0, __values(h)), p = d.next(); !p.done; p = d.next()) {
            var f = p.value;
            this.dataset.addExample(f.example);
          }
        } catch (e3) {
          a = { error: e3 };
        } finally {
          try {
            p && !p.done && (i = d.return) && i.call(d);
          } finally {
            if (a) throw a.error;
          }
        }
      }
    } catch (e3) {
      r = { error: e3 };
    } finally {
      try {
        u && !u.done && (n = l.return) && n.call(l);
      } finally {
        if (r) throw r.error;
      }
    }
    this.collateTransferWords();
  }, t.prototype.serializeExamples = function(e2) {
    return this.dataset.serialize(e2);
  }, t.prototype.collateTransferWords = function() {
    this.words = this.dataset.getVocabulary();
  }, t.prototype.collectTransferDataAsTensors = function(e2, t2) {
    var r = this.nonBatchInputShape[0];
    e2 = e2 || DEFAULT_WINDOW_HOP_RATIO;
    var n = Math.round(e2 * r), a = this.dataset.getData(null, __assign({ numFrames: r, hopFrames: n }, t2));
    return { xs: a.xs, ys: a.ys };
  }, t.prototype.collectTransferDataAsTfDataset = function(e2, t2, r, n) {
    void 0 === t2 && (t2 = 0.15), void 0 === r && (r = 32);
    var a = this.nonBatchInputShape[0];
    e2 = e2 || DEFAULT_WINDOW_HOP_RATIO;
    var i = Math.round(e2 * a);
    return this.dataset.getData(null, __assign({ numFrames: a, hopFrames: i, getDataset: true, datasetBatchSize: r, datasetValidationSplit: t2 }, n));
  }, t.prototype.train = function(e2) {
    return __awaiter(this, void 0, void 0, function() {
      var t2, r = this;
      return __generator(this, function(n) {
        return util_exports.assert(null != this.words && this.words.length > 0, function() {
          return "Cannot train transfer-learning model '" + r.name + "' because no transfer learning example has been collected.";
        }), util_exports.assert(this.words.length > 1, function() {
          return "Cannot train transfer-learning model '" + r.name + "' because only 1 word label ('" + JSON.stringify(r.words) + "') has been collected for transfer learning. Requires at least 2.";
        }), null != e2.fineTuningEpochs && util_exports.assert(e2.fineTuningEpochs >= 0 && Number.isInteger(e2.fineTuningEpochs), function() {
          return "If specified, fineTuningEpochs must be a non-negative integer, but received " + e2.fineTuningEpochs;
        }), null == e2 && (e2 = {}), null == this.model && this.createTransferModelFromBaseModel(), this.secondLastBaseDenseLayer.trainable = false, this.model.compile({ loss: "categoricalCrossentropy", optimizer: e2.optimizer || "sgd", metrics: ["acc"] }), t2 = null == e2.fitDatasetDurationMillisThreshold ? 6e4 : e2.fitDatasetDurationMillisThreshold, this.dataset.durationMillis() > t2 ? (console.log("Detected large dataset: total duration = " + this.dataset.durationMillis() + " ms > " + t2 + " ms. Training transfer model using fitDataset() instead of fit()"), [2, this.trainOnDataset(e2)]) : [2, this.trainOnTensors(e2)];
      });
    });
  }, t.prototype.trainOnDataset = function(e2) {
    return __awaiter(this, void 0, void 0, function() {
      var t2, r, n, a, i, o, s, l, u;
      return __generator(this, function(c) {
        switch (c.label) {
          case 0:
            return util_exports.assert(e2.epochs > 0, function() {
              return "Invalid config.epochs";
            }), t2 = null == e2.batchSize ? 32 : e2.batchSize, r = e2.windowHopRatio || DEFAULT_WINDOW_HOP_RATIO, n = __read(this.collectTransferDataAsTfDataset(r, e2.validationSplit, t2, { augmentByMixingNoiseRatio: e2.augmentByMixingNoiseRatio }), 2), a = n[0], i = n[1], o = util_exports.now(), [4, this.model.fitDataset(a, { epochs: e2.epochs, validationData: e2.validationSplit > 0 ? i : null, callbacks: null == e2.callback ? null : [e2.callback] })];
          case 1:
            return s = c.sent(), console.log("fitDataset() took " + (util_exports.now() - o).toFixed(2) + " ms"), null != e2.fineTuningEpochs && e2.fineTuningEpochs > 0 ? (l = util_exports.now(), [4, this.fineTuningUsingTfDatasets(e2, a, i)]) : [3, 3];
          case 2:
            return u = c.sent(), console.log("fitDataset() (fine-tuning) took " + (util_exports.now() - l).toFixed(2) + " ms"), [2, [s, u]];
          case 3:
            return [2, s];
        }
      });
    });
  }, t.prototype.trainOnTensors = function(e2) {
    return __awaiter(this, void 0, void 0, function() {
      var t2, r, n, a, i, o, s, l, u, c;
      return __generator(this, function(h) {
        switch (h.label) {
          case 0:
            t2 = e2.windowHopRatio || DEFAULT_WINDOW_HOP_RATIO, r = this.collectTransferDataAsTensors(t2, { augmentByMixingNoiseRatio: e2.augmentByMixingNoiseRatio }), n = r.xs, a = r.ys, console.log("Training data: xs.shape = " + n.shape + ", ys.shape = " + a.shape), h.label = 1;
          case 1:
            return h.trys.push([1, , 6, 7]), null != e2.validationSplit ? (l = balancedTrainValSplit(n, a, e2.validationSplit), i = l.trainXs, o = l.trainYs, s = [l.valXs, l.valYs]) : (i = n, o = a), [4, this.model.fit(i, o, { epochs: null == e2.epochs ? 20 : e2.epochs, validationData: s, batchSize: e2.batchSize, callbacks: null == e2.callback ? null : [e2.callback] })];
          case 2:
            return u = h.sent(), null != e2.fineTuningEpochs && e2.fineTuningEpochs > 0 ? [4, this.fineTuningUsingTensors(e2, i, o, s)] : [3, 4];
          case 3:
            return c = h.sent(), [2, [u, c]];
          case 4:
            return [2, u];
          case 5:
            return [3, 7];
          case 6:
            return dispose([n, a, i, o, s]), [7];
          case 7:
            return [2];
        }
      });
    });
  }, t.prototype.fineTuningUsingTfDatasets = function(e2, t2, r) {
    return __awaiter(this, void 0, void 0, function() {
      var n, a, i;
      return __generator(this, function(o) {
        switch (o.label) {
          case 0:
            return n = this.secondLastBaseDenseLayer.trainable, this.secondLastBaseDenseLayer.trainable = true, a = null == e2.fineTuningOptimizer ? "sgd" : e2.fineTuningOptimizer, this.model.compile({ loss: "categoricalCrossentropy", optimizer: a, metrics: ["acc"] }), [4, this.model.fitDataset(t2, { epochs: e2.fineTuningEpochs, validationData: r, callbacks: null == e2.callback ? null : [e2.callback] })];
          case 1:
            return i = o.sent(), this.secondLastBaseDenseLayer.trainable = n, [2, i];
        }
      });
    });
  }, t.prototype.fineTuningUsingTensors = function(e2, t2, r, n) {
    return __awaiter(this, void 0, void 0, function() {
      var a, i, o;
      return __generator(this, function(s) {
        switch (s.label) {
          case 0:
            return a = this.secondLastBaseDenseLayer.trainable, this.secondLastBaseDenseLayer.trainable = true, i = null == e2.fineTuningOptimizer ? "sgd" : e2.fineTuningOptimizer, this.model.compile({ loss: "categoricalCrossentropy", optimizer: i, metrics: ["acc"] }), [4, this.model.fit(t2, r, { epochs: e2.fineTuningEpochs, validationData: n, batchSize: e2.batchSize, callbacks: null == e2.fineTuningCallback ? null : [e2.fineTuningCallback] })];
          case 1:
            return o = s.sent(), this.secondLastBaseDenseLayer.trainable = a, [2, o];
        }
      });
    });
  }, t.prototype.evaluate = function(e2) {
    return __awaiter(this, void 0, void 0, function() {
      var t2, r = this;
      return __generator(this, function(n) {
        return util_exports.assert(null != e2.wordProbThresholds && e2.wordProbThresholds.length > 0, function() {
          return "Received null or empty wordProbThresholds";
        }), t2 = 0, util_exports.assert(this.words[t2] === BACKGROUND_NOISE_TAG, function() {
          return "Cannot perform evaluation when the first tag is not " + BACKGROUND_NOISE_TAG;
        }), [2, tidy(function() {
          for (var n2 = [], a = 0, i = r.collectTransferDataAsTensors(e2.windowHopRatio), o = i.xs, s = i.ys.argMax(-1).dataSync(), l = r.model.predict(o), u = max(slice(l, [0, 1], [l.shape[0], l.shape[1] - 1]), -1), c = l.shape[0], h = 0; h < e2.wordProbThresholds.length; ++h) {
            for (var d = e2.wordProbThresholds[h], p = u.greater(scalar(d)).dataSync(), f = 0, m = 0, g = 0, v = 0, y = 0; y < c; ++y) s[y] === t2 ? (f++, p[y] && g++) : (m++, p[y] && v++);
            var w = g / f, b = v / m;
            n2.push({ probThreshold: d, fpr: w, tpr: b }), console.log("ROC thresh=" + d + ": fpr=" + w.toFixed(4) + ", tpr=" + b.toFixed(4)), h > 0 && (a += Math.abs(n2[h - 1].fpr - n2[h].fpr) * (n2[h - 1].tpr + n2[h].tpr) / 2);
          }
          return { rocCurve: n2, auc: a };
        })];
      });
    });
  }, t.prototype.createTransferModelFromBaseModel = function() {
    var e2 = this;
    util_exports.assert(null != this.words, function() {
      return "No word example is available for tranfer-learning model of name " + e2.name;
    });
    for (var t2 = this.baseModel.layers, r = t2.length - 2; r >= 0 && "dense" !== t2[r].getClassName().toLowerCase(); ) r--;
    if (r < 0) throw new Error("Cannot find a hidden dense layer in the base model.");
    this.secondLastBaseDenseLayer = t2[r];
    var n = this.secondLastBaseDenseLayer.output;
    this.transferHead = sequential(), this.transferHead.add(exports_layers_exports.dense({ units: this.words.length, activation: "softmax", inputShape: n.shape.slice(1), name: "NewHeadDense" }));
    var a = this.transferHead.apply(n);
    this.model = model({ inputs: this.baseModel.inputs, outputs: a });
  }, t.prototype.modelInputShape = function() {
    return this.baseModel.inputs[0].shape;
  }, t.prototype.getMetadata = function() {
    return { tfjsSpeechCommandsVersion: version, modelName: this.name, timeStamp: (/* @__PURE__ */ new Date()).toISOString(), wordLabels: this.wordLabels() };
  }, t.prototype.save = function(e2) {
    return __awaiter(this, void 0, void 0, function() {
      var t2, r, n;
      return __generator(this, function(a) {
        return t2 = null != e2, e2 = e2 || getCanonicalSavePath(this.name), t2 || (r = localStorageWrapper.localStorage.getItem(SAVED_MODEL_METADATA_KEY), (n = null == r ? {} : JSON.parse(r))[this.name] = this.getMetadata(), localStorageWrapper.localStorage.setItem(SAVED_MODEL_METADATA_KEY, JSON.stringify(n))), console.log("Saving model to " + e2), [2, this.model.save(e2)];
      });
    });
  }, t.prototype.load = function(e2) {
    return __awaiter(this, void 0, void 0, function() {
      var t2, r, n;
      return __generator(this, function(a) {
        switch (a.label) {
          case 0:
            if (t2 = null != e2, e2 = e2 || getCanonicalSavePath(this.name), !t2) {
              if (null == (r = JSON.parse(localStorageWrapper.localStorage.getItem(SAVED_MODEL_METADATA_KEY))) || null == r[this.name]) throw new Error("Cannot find metadata for transfer model named " + this.name + '"');
              this.words = r[this.name].wordLabels, console.log("Loaded word list for model named " + this.name + ": " + this.words);
            }
            return n = this, [4, loadLayersModel(e2)];
          case 1:
            return n.model = a.sent(), console.log("Loaded model from " + e2 + ":"), this.model.summary(), [2];
        }
      });
    });
  }, t.prototype.createTransfer = function(e2) {
    throw new Error("Creating transfer-learned recognizer from a transfer-learned recognizer is not supported.");
  }, t;
}(BrowserFftSpeechCommandRecognizer);
function getCanonicalSavePath(e) {
  return "" + SAVE_PATH_PREFIX + e;
}
function listSavedTransferModels() {
  return __awaiter(this, void 0, void 0, function() {
    var e, t, r;
    return __generator(this, function(n) {
      switch (n.label) {
        case 0:
          return [4, io_exports.listModels()];
        case 1:
          for (r in e = n.sent(), t = [], e) r.startsWith(SAVE_PATH_PREFIX) && t.push(r.slice(SAVE_PATH_PREFIX.length));
          return [2, t];
      }
    });
  });
}
function deleteSavedTransferModel(e) {
  return __awaiter(this, void 0, void 0, function() {
    var t;
    return __generator(this, function(r) {
      switch (r.label) {
        case 0:
          return null == (t = JSON.parse(localStorageWrapper.localStorage.getItem(SAVED_MODEL_METADATA_KEY))) && (t = {}), null != t[e] && delete t[e], localStorageWrapper.localStorage.setItem(SAVED_MODEL_METADATA_KEY, JSON.stringify(t)), [4, io_exports.removeModel(getCanonicalSavePath(e))];
        case 1:
          return r.sent(), [2];
      }
    });
  });
}
function create(e, t, r, n) {
  if (util_exports.assert(null == r && null == n || null != r && null != n, function() {
    return "customModelURL and customMetadataURL must be both provided or both not provided.";
  }), null != r && util_exports.assert(null == t, function() {
    return "vocabulary name must be null or undefined when modelURL is provided.";
  }), "BROWSER_FFT" === e) return new BrowserFftSpeechCommandRecognizer(t, r, n);
  throw "SOFT_FFT" === e ? new Error("SOFT_FFT SpeechCommandRecognizer has not been implemented yet.") : new Error("Invalid fftType: '" + e + "'");
}
var utils = { concatenateFloat32Arrays, normalizeFloat32Array, normalize, playRawAudio };
export {
  BACKGROUND_NOISE_TAG,
  Dataset,
  UNKNOWN_TAG,
  create,
  deleteSavedTransferModel,
  getMaxIntensityFrameIndex,
  listSavedTransferModels,
  spectrogram2IntensityCurve,
  utils,
  version
};
/*! Bundled license information:

@tensorflow-models/speech-commands/dist/speech-commands.esm.js:
  (**
      * @license
      * Copyright 2021 Google LLC. All Rights Reserved.
      * Licensed under the Apache License, Version 2.0 (the "License");
      * you may not use this file except in compliance with the License.
      * You may obtain a copy of the License at
      *
      * http://www.apache.org/licenses/LICENSE-2.0
      *
      * Unless required by applicable law or agreed to in writing, software
      * distributed under the License is distributed on an "AS IS" BASIS,
      * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      * See the License for the specific language governing permissions and
      * limitations under the License.
      * =============================================================================
      *)
*/
//# sourceMappingURL=@tensorflow-models_speech-commands.js.map
